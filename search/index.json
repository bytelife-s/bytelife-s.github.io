[{"content":"Problem Example for setting up monitoring for Docker environment using ELK and Prometheus-Grafana.\nGoal:\nBuild logging monitoring system using ELK stack to monitor logs from Docker containers automatically.\nBuild metrics monitoring system using Prometheus and Grafana to monitor Docker containers and linux host automatically.\nBuild alerting system using Prometheus Alertmanager to send alerts via AWS SES email\nAdd Kong API Gateway as host entry for Cloudflare Tunnel and monitor its logs and metrics\nHigh Level Architecture Components and ports:\nPrometheus (9090)\nGrafana (3000)\nNode Exporter (9100)\ncAdvisor (8080)\nElasticsearch (9200)\nKibana (5601)\nLogstash (5044)\nAlertManager (9093)\nProject structure:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 monitor/ ├── docker-compose.yml # Docker Compose configuration ├── alertmanager/ # AlertManager configuration │ └── config.yml ├── prometheus/ # Prometheus configuration │ └── prometheus.yml │ └── rules/ | └── alert.rules # Prometheus alerting rules ├── logging/ # ELK stack configuration │ └── config/ # Filebeat and Logstash configs │ └── filebeat.yml │ └── logstash.conf ├── kong/ # Kong API Gateway configuration | └── docker-compose.yml | └── setup-logging.sh Main Docker Compose Configuration monitor/docker-compose.yml\nin this file, we define the services and their configurations. We also define the volumes and networks for the services.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 version: \u0026#39;3.8\u0026#39; services: prometheus: image: prom/prometheus:latest container_name: prometheus ports: - \u0026#34;9090:9090\u0026#34; volumes: - ./prometheus:/etc/prometheus - prometheus_data:/prometheus command: - \u0026#39;--config.file=/etc/prometheus/prometheus.yml\u0026#39; - \u0026#39;--storage.tsdb.path=/prometheus\u0026#39; - \u0026#39;--web.console.libraries=/usr/share/prometheus/console_libraries\u0026#39; - \u0026#39;--web.console.templates=/usr/share/prometheus/consoles\u0026#39; restart: unless-stopped alertmanager: image: prom/alertmanager:latest container_name: alertmanager ports: - \u0026#34;9093:9093\u0026#34; volumes: - ./alertmanager:/etc/alertmanager command: - \u0026#39;--config.file=/etc/alertmanager/config.yml\u0026#39; - \u0026#39;--storage.path=/alertmanager\u0026#39; restart: unless-stopped grafana: image: grafana/grafana:latest container_name: grafana ports: - \u0026#34;3000:3000\u0026#34; volumes: - grafana_data:/var/lib/grafana environment: - GF_SECURITY_ADMIN_USER=admin - GF_SECURITY_ADMIN_PASSWORD=admin restart: unless-stopped depends_on: - prometheus node-exporter: image: prom/node-exporter:latest container_name: node-exporter ports: - \u0026#34;9100:9100\u0026#34; volumes: - /proc:/host/proc:ro - /sys:/host/sys:ro - /:/rootfs:ro command: - \u0026#39;--path.procfs=/host/proc\u0026#39; - \u0026#39;--path.sysfs=/host/sys\u0026#39; - \u0026#39;--path.rootfs=/rootfs\u0026#39; - \u0026#39;--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)\u0026#39; restart: unless-stopped cadvisor: image: gcr.io/cadvisor/cadvisor:latest container_name: cadvisor ports: - \u0026#34;8080:8080\u0026#34; volumes: - /:/rootfs:ro - /var/run:/var/run:ro - /sys:/sys:ro - /var/lib/docker/:/var/lib/docker:ro - /dev/disk/:/dev/disk:ro devices: - /dev/kmsg:/dev/kmsg restart: unless-stopped elasticsearch: image: docker.elastic.co/elasticsearch/elasticsearch:8.11.1 container_name: elasticsearch environment: - discovery.type=single-node - ES_JAVA_OPTS=-Xms512m -Xmx512m - xpack.security.enabled=false ports: - \u0026#34;9200:9200\u0026#34; volumes: - elasticsearch_data:/usr/share/elasticsearch/data restart: unless-stopped logstash: image: docker.elastic.co/logstash/logstash:8.11.1 container_name: logstash ports: - \u0026#34;5044:5044\u0026#34; - \u0026#34;5000:5000/tcp\u0026#34; - \u0026#34;5000:5000/udp\u0026#34; volumes: - ./logging/config/logstash.conf:/usr/share/logstash/pipeline/logstash.conf environment: - LS_JAVA_OPTS=-Xms256m -Xmx256m depends_on: - elasticsearch restart: unless-stopped kibana: image: docker.elastic.co/kibana/kibana:8.11.1 container_name: kibana ports: - \u0026#34;5601:5601\u0026#34; environment: - ELASTICSEARCH_HOSTS=http://elasticsearch:9200 depends_on: - elasticsearch restart: unless-stopped filebeat: image: docker.elastic.co/beats/filebeat:8.11.1 container_name: filebeat user: root volumes: - ./logging/config/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro - /var/lib/docker/containers:/var/lib/docker/containers:ro - /var/run/docker.sock:/var/run/docker.sock:ro - filebeat_data:/usr/share/filebeat/data environment: - strict.perms=false - ELASTIC_HOSTS=elasticsearch:9200 - KIBANA_HOSTS=kibana:5601 - LOGSTASH_HOSTS=logstash:5044 command: [\u0026#34;--strict.perms=false\u0026#34;] depends_on: - elasticsearch - logstash restart: unless-stopped volumes: prometheus_data: grafana_data: elasticsearch_data: filebeat_data: networks: default: host: external: true name: host Logging Pipeling Configuration monitor/logging/config/logstash.conf\nin this file, we define the Logstash pipeline configuration to process logs from Docker containers and kong and send them to Elasticsearch.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 input { tcp { port =\u0026gt; 5000 codec =\u0026gt; json type =\u0026gt; \u0026#34;kong\u0026#34; } beats { port =\u0026gt; 5044 type =\u0026gt; \u0026#34;beats\u0026#34; } } filter { if [type] == \u0026#34;beats\u0026#34; { if [container] { if [container][labels][com.docker.compose.service] { mutate { add_field =\u0026gt; { \u0026#34;service.name\u0026#34; =\u0026gt; \u0026#34;%{[container][labels][com.docker.compose.service]}\u0026#34; } } } else { mutate { copy =\u0026gt; { \u0026#34;[container][name]\u0026#34; =\u0026gt; \u0026#34;service.name\u0026#34; } } } } } if [type] == \u0026#34;kong\u0026#34; { mutate { add_field =\u0026gt; { \u0026#34;service.name\u0026#34; =\u0026gt; \u0026#34;kong\u0026#34; } } } if [source] == \u0026#34;docker\u0026#34; { mutate { rename =\u0026gt; { \u0026#34;[container][name]\u0026#34; =\u0026gt; \u0026#34;service.name\u0026#34; } } } date { match =\u0026gt; [\u0026#34;@timestamp\u0026#34;, \u0026#34;ISO8601\u0026#34;] target =\u0026gt; \u0026#34;@timestamp\u0026#34; } } output { elasticsearch { hosts =\u0026gt; [\u0026#34;elasticsearch:9200\u0026#34;] index =\u0026gt; \u0026#34;logstash-%{+YYYY.MM.dd}\u0026#34; manage_template =\u0026gt; true } # For debugging stdout { codec =\u0026gt; rubydebug } } monitor/logging/config/filebeat.yml\nin this file, we define the Filebeat configuration to collect logs from Docker containers and send them to Logstash.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 filebeat.inputs: - type: filestream id: docker-logs paths: - /var/lib/docker/containers/*/*.log parsers: - container: ~ processors: - add_docker_metadata: host: \u0026#34;unix:///var/run/docker.sock\u0026#34; - decode_json_fields: fields: [\u0026#34;message\u0026#34;, \u0026#34;log\u0026#34;] target: \u0026#34;\u0026#34; overwrite_keys: true - drop_event: when: contains: container.image.name: \u0026#34;docker.elastic.co/logstash/logstash\u0026#34; - rename: fields: - from: \u0026#34;container.name\u0026#34; to: \u0026#34;service.name\u0026#34; ignore_missing: true output.logstash: hosts: [\u0026#34;logstash:5044\u0026#34;] logging.level: debug logging.to_files: true logging.files: path: /usr/share/filebeat/logs name: filebeat.log keepfiles: 7 permissions: 0644 setup.ilm.enabled: false setup.template.enabled: false Metrics Monitoring Configuration monitor/prometheus/prometheus.yml\nin this file, we define the Prometheus configuration to scrape metrics from Node Exporter, cAdvisor, and Kong.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 global: scrape_interval: 15s evaluation_interval: 15s rule_files: - \u0026#34;rules/alert.rules.yml\u0026#34; alerting: alertmanagers: - static_configs: - targets: - alertmanager:9093 scrape_configs: - job_name: \u0026#39;prometheus\u0026#39; static_configs: - targets: [\u0026#39;localhost:9090\u0026#39;] - job_name: \u0026#39;node-exporter\u0026#39; static_configs: - targets: [\u0026#39;node-exporter:9100\u0026#39;] - job_name: \u0026#39;cadvisor\u0026#39; static_configs: - targets: [\u0026#39;cadvisor:8080\u0026#39;] - job_name: \u0026#39;kong\u0026#39; static_configs: - targets: [\u0026#39;172.17.0.1:8001\u0026#39;] metrics_path: /metrics Alert Configuration monitor/prometheus/rules/alert.rules.yml\nin this file, we define the Prometheus alerting rules to trigger alerts based on metrics.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 groups: - name: cpu_alerts rules: - alert: HighCPUUsage expr: 100 - (avg by(instance) (irate(node_cpu_seconds_total{mode=\u0026#34;idle\u0026#34;}[5m])) * 100) \u0026gt; 80 for: 15m labels: severity: warning annotations: summary: \u0026#34;High CPU usage detected\u0026#34; description: \u0026#34;CPU usage has been above 80% for more than 5 minute.\u0026#34; value: \u0026#34;{{ $value }}%\u0026#34; - name: container_alerts rules: - alert: ContainerHighCPUUsage expr: sum(rate(container_cpu_usage_seconds_total{container!=\u0026#34;\u0026#34;}[5m])) by (container) * 100 \u0026gt; 80 for: 15m labels: severity: warning annotations: summary: \u0026#34;Container High CPU Usage\u0026#34; description: \u0026#34;Container {{ $labels.container }} CPU usage is above 80% for more than 5 minutes\u0026#34; value: \u0026#34;{{ $value }}%\u0026#34; - alert: ContainerHighMemoryUsage expr: (container_memory_usage_bytes{container!=\u0026#34;\u0026#34;} / container_spec_memory_limit_bytes{container!=\u0026#34;\u0026#34;} * 100) \u0026gt; 80 for: 15m labels: severity: warning annotations: summary: \u0026#34;Container High Memory Usage\u0026#34; description: \u0026#34;Container {{ $labels.container }} memory usage is above 80% for more than 5 minutes\u0026#34; value: \u0026#34;{{ $value }}%\u0026#34; - name: kong_alerts rules: - alert: KongHighLatency expr: histogram_quantile(0.95, sum(rate(kong_latency_bucket{type=\u0026#34;request\u0026#34;}[5m])) by (le)) \u0026gt; 2000 for: 5m labels: severity: warning annotations: summary: \u0026#34;Kong High Latency\u0026#34; description: \u0026#34;95th percentile of Kong request latency is above 2 seconds\u0026#34; value: \u0026#34;{{ $value }}ms\u0026#34; - alert: KongHighErrorRate expr: sum(rate(kong_http_requests_total{code=~\u0026#34;5..\u0026#34;}[5m])) / sum(rate(kong_http_requests_total[5m])) * 100 \u0026gt; 5 for: 5m labels: severity: warning annotations: summary: \u0026#34;Kong High Error Rate\u0026#34; description: \u0026#34;Error rate is above 5% for the last 5 minutes\u0026#34; value: \u0026#34;{{ $value }}%\u0026#34; - alert: KongHighTotalRequests expr: sum(rate(kong_http_requests_total[5m])) \u0026gt; 1000 for: 5m labels: severity: warning annotations: summary: \u0026#34;Kong High Request Rate\u0026#34; description: \u0026#34;Total requests per second is above 1000 for the last 5 minutes\u0026#34; value: \u0026#34;{{ $value }} req/s\u0026#34; monitor/alertmanager/config.yml\nin this file, we define the AlertManager configuration to send alerts via email.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 global: resolve_timeout: 5m smtp_from: \u0026#34;\u0026lt;email\u0026gt;\u0026#34; # Replace with your SES verified email smtp_smarthost: \u0026#34;email-smtp.us-west-2.amazonaws.com:587\u0026#34; # SES SMTP endpoint for Oregon region smtp_auth_username: \u0026#34;\u0026lt;username\u0026gt;\u0026#34; # Replace with your SES SMTP credentials smtp_auth_password: \u0026#34;\u0026lt;password\u0026gt;\u0026#34; # Replace with your SES SMTP credentials smtp_require_tls: true route: group_by: [\u0026#39;alertname\u0026#39;] group_wait: 30s group_interval: 5m repeat_interval: 1h receiver: \u0026#39;email-notifications\u0026#39; receivers: - name: \u0026#39;email-notifications\u0026#39; email_configs: - to: \u0026#34;\u0026lt;email\u0026gt;\u0026#34; # Replace with recipient email send_resolved: true Kong API Gateway Configuration monitor/kong/docker-compose.yml\nin this file, we define the Kong API Gateway configuration to expose the Kong Admin API and Proxy API.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 version: \u0026#39;3.8\u0026#39; services: kong-database: image: postgres:13 container_name: kong-database environment: POSTGRES_USER: kong POSTGRES_DB: kong POSTGRES_PASSWORD: kongpass volumes: - kong_data:/var/lib/postgresql/data ports: - \u0026#34;5432:5432\u0026#34; healthcheck: test: [\u0026#34;CMD\u0026#34;, \u0026#34;pg_isready\u0026#34;, \u0026#34;-U\u0026#34;, \u0026#34;kong\u0026#34;] interval: 5s timeout: 5s retries: 5 restart: unless-stopped kong-migration: image: kong:3.4 container_name: kong-migration network_mode: \u0026#34;host\u0026#34; command: kong migrations bootstrap environment: KONG_DATABASE: postgres KONG_PG_HOST: localhost KONG_PG_PORT: 5432 KONG_PG_USER: kong KONG_PG_PASSWORD: kongpass depends_on: kong-database: condition: service_healthy restart: on-failure kong: image: kong:3.4 container_name: kong network_mode: \u0026#34;host\u0026#34; environment: KONG_DATABASE: postgres KONG_PG_HOST: localhost KONG_PG_PORT: 5432 KONG_PG_USER: kong KONG_PG_PASSWORD: kongpass KONG_PROXY_ACCESS_LOG: /dev/stdout KONG_ADMIN_ACCESS_LOG: /dev/stdout KONG_PROXY_ERROR_LOG: /dev/stderr KONG_ADMIN_ERROR_LOG: /dev/stderr KONG_ADMIN_LISTEN: 0.0.0.0:8001 KONG_PROXY_LISTEN: 0.0.0.0:8000, 0.0.0.0:8443 ssl KONG_STATUS_LISTEN: 0.0.0.0:8100 KONG_PLUGINS: bundled,prometheus,tcp-log KONG_CUSTOM_PLUGINS: tcp-log depends_on: kong-migration: condition: service_completed_successfully healthcheck: test: [\u0026#34;CMD\u0026#34;, \u0026#34;kong\u0026#34;, \u0026#34;health\u0026#34;] interval: 10s timeout: 10s retries: 10 restart: unless-stopped volumes: kong_data: monitor/kong/setup-logging.sh\nin this file, we define the script to configure TCP logging for Kong services.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 #!/bin/bash # Wait for Kong to be ready echo \u0026#34;Waiting for Kong to be ready...\u0026#34; while ! curl -s http://localhost:8001 \u0026gt; /dev/null; do sleep 5 done # Configure TCP logging for all services echo \u0026#34;Configuring TCP logging for Kong...\u0026#34; curl -X POST http://localhost:8001/plugins \\ --data \u0026#34;name=tcp-log\u0026#34; \\ --data \u0026#34;config.host=localhost\u0026#34; \\ --data \u0026#34;config.port=5000\u0026#34; \\ --data \u0026#34;config.timeout=10000\u0026#34; \\ --data \u0026#34;config.keepalive=60000\u0026#34; echo \u0026#34;TCP logging configuration complete!\u0026#34; Start Monitoring System docker compose up -d to start the monitoring system.\ndocker compose -f kong/docker-compose.yml up -d to start the Kong API Gateway.\n./kong/setup-logging.sh to configure TCP logging for Kong services.\nLogin to Grafana at http://localhost:3000 then create prometheus data source and import dashboards.\nlogin to Kibana at http://localhost:5601 then create index pattern logstash-*\nResult Prometheus Dashboard Grafana Linux Dashboard Grafana Docker Dashboard Grafana Kong Dashboard Prometheus Alert Prometheus Alertmanager ELK Dashboard Summary In this example, we built a monitoring system for Docker environment using ELK and Prometheus-Grafana. We configured logging monitoring using ELK stack to monitor logs from Docker containers and metrics monitoring using Prometheus and Grafana to monitor Docker containers and linux host. We also configured alerting system using Prometheus Alertmanager to send alerts via email. Finally, we added Kong API Gateway as host entry and monitored its logs and metrics.\n","date":"2024-12-15T00:00:00Z","permalink":"https://bytelife-s.github.io/p/setup-elk-and-prometheus-grafana-monitoring-for-docker-environment/","title":"Setup ELK and Prometheus-Grafana Monitoring for Docker Environment"},{"content":"Background CompletableFuture was introduced as a Java 8 and is helpful for asynchronous programming. It allows developers to write non-blocking code and execute tasks in parallel. However, it can be challenging to understand how to use CompletableFuture effectively. This post will provide a comprehensive guide to using CompletableFuture in Java.\nCreate CompletableFuture The supplyAsync method is used to create a CompletableFuture that returns a value, while the runAsync method is used to create a CompletableFuture that does not return a value. 1 2 3 4 5 6 7 public static \u0026lt;U\u0026gt; CompletableFuture\u0026lt;U\u0026gt; supplyAsync(Supplier\u0026lt;U\u0026gt; supplier){..} public static \u0026lt;U\u0026gt; CompletableFuture\u0026lt;U\u0026gt; supplyAsync(Supplier\u0026lt;U\u0026gt; supplier,Executor executor){..} public static CompletableFuture\u0026lt;Void\u0026gt; runAsync(Runnable runnable){..} public static CompletableFuture\u0026lt;Void\u0026gt; runAsync(Runnable runnable,Executor executor){..} Get Result The get method is used to retrieve the result of a CompletableFuture. It is a blocking call that waits for the result to be available.\nthe get with timeout method is used to retrieve the result of a CompletableFuture with a timeout. It is a blocking call that waits for the result to be available within the specified time.\nthe getNow method is used to retrieve the result of a CompletableFuture. It returns the specified value if the result is not available.\nthe join method is used to retrieve the result of a CompletableFuture. It is a non-blocking call that waits for the result to be available. No checked exception is thrown.\n1 2 3 4 5 6 7 public T get() public T get(long timeout, TimeUnit unit) public T getNow(T valueIfAbsent) public T join() Callback thenRun/thenRunAsync the 2nd task doest not dependent on the 1st stage\u0026rsquo;s result\nthe 2nd task does not return a value\n1 2 3 4 5 public CompletableFuture\u0026lt;Void\u0026gt; thenRun(Runnable action) public CompletableFuture\u0026lt;Void\u0026gt; thenRunAsync(Runnable action) public CompletableFuture\u0026lt;Void\u0026gt; thenRunAsync(Runnable action Executor executor) The difference between thenRun and thenRunAsync is that thenRun runs in the same thread as the previous stage, while thenRunAsync runs in a different thread. For example, the 1st task is executed in the defined thread pool, and the 2nd task is executed in the forkJoin pool if no other pool is specified. Same difference between other methods.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 public static void main(String[] args) throws Exception { ExecutorService executor = Executors.newFixedThreadPool(2); System.out.println(\u0026#34;\\n=== thenRun vs thenRunAsync ===\u0026#34;); CompletableFuture.supplyAsync(() -\u0026gt; { System.out.println(\u0026#34;First task running in thread: \u0026#34; + Thread.currentThread().getName()); return \u0026#34;Some Result\u0026#34;; }, executor).thenRun(() -\u0026gt; { System.out.println(\u0026#34;thenRun - Second task running in thread: \u0026#34; + Thread.currentThread().getName()); }); CompletableFuture.supplyAsync(() -\u0026gt; { System.out.println(\u0026#34;First task running in thread: \u0026#34; + Thread.currentThread().getName()); return \u0026#34;Some Result\u0026#34;; }, executor).thenRunAsync(() -\u0026gt; { System.out.println(\u0026#34;thenRunAsync - Second task running in thread: \u0026#34; + Thread.currentThread().getName()); }); executor.shutdown(); executor.awaitTermination(5, TimeUnit.SECONDS); } 1 2 3 4 5 === thenRun vs thenRunAsync === First task running in thread: pool-1-thread-1 thenRun - Second task running in thread: main First task running in thread: pool-1-thread-2 thenRunAsync - Second task running in thread: ForkJoinPool.commonPool-worker-1 thenAccept/thenAcceptAsync the 2nd task can access the 1st stage\u0026rsquo;s result\nthe 2nd task does not return a value\n1 2 3 4 5 public CompletableFuture\u0026lt;Void\u0026gt; thenAccept(Consumer\u0026lt;? super T\u0026gt; action) public CompletableFuture\u0026lt;Void\u0026gt; thenAcceptAsync(Consumer\u0026lt;? super T\u0026gt; action) public CompletableFuture\u0026lt;Void\u0026gt; thenAcceptAsync(Consumer\u0026lt;? super T\u0026gt; action, Executor executor) 1 2 3 4 5 6 7 8 System.out.println(\u0026#34;\\n=== thenAccept Example ===\u0026#34;); CompletableFuture.supplyAsync(() -\u0026gt; { System.out.println(\u0026#34;Calculating price...\u0026#34;); return 100.0; // Simulating price calculation }, executor).thenAccept(price -\u0026gt; { System.out.println(\u0026#34;Price received: $\u0026#34; + price); // Process the price but don\u0026#39;t return anything }); 1 2 3 === thenAccept Example === Calculating price... Price received: $100.0 thenApply/thenApplyAsync the 2nd task can access the 1st stage\u0026rsquo;s result\nthe 2nd task returns a value\n1 2 3 4 5 public \u0026lt;U\u0026gt; CompletableFuture\u0026lt;U\u0026gt; thenApply(Function\u0026lt;? super T,? extends U\u0026gt; fn) public \u0026lt;U\u0026gt; CompletableFuture\u0026lt;U\u0026gt; thenApplyAsync(Function\u0026lt;? super T,? extends U\u0026gt; fn) public \u0026lt;U\u0026gt; CompletableFuture\u0026lt;U\u0026gt; thenApplyAsync(Function\u0026lt;? super T,? extends U\u0026gt; fn, Executor executor) 1 2 3 4 5 6 7 8 9 System.out.println(\u0026#34;\\n=== thenApply Example ===\u0026#34;); CompletableFuture\u0026lt;Double\u0026gt; finalPrice = CompletableFuture.supplyAsync(() -\u0026gt; { System.out.println(\u0026#34;Calculating base price...\u0026#34;); return 100.0; // Base price }, executor).thenApply(price -\u0026gt; { System.out.println(\u0026#34;Adding tax...\u0026#34;); return price * 1.2; // Adding 20% tax }); System.out.println(\u0026#34;Final price with tax: $\u0026#34; + finalPrice.get()); 1 2 3 4 === thenApply Example === Calculating base price... Adding tax... Final price with tax: $120.0 thenCompose/thenComposeAsync The thenCompose method is used to chain multiple CompletableFutures together.\nThe thenCompose method takes a Function that returns a CompletableFuture.\nThe differenvce between thenApply and thenCompose is that thenApply returns a value, while thenCompose returns a CompletableFuture. If you retuen a CompletableFuture in thenApply, it will be wrapped in another CompletableFuture, which means you will have a nested CompletableFuture. So use thenCompose if you want to chain multiple CompletableFutures together.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 System.out.println(\u0026#34;\\n=== thenApply vs thenCompose Difference ===\u0026#34;); // Using thenApply - results in nested CompletableFuture CompletableFuture\u0026lt;CompletableFuture\u0026lt;String\u0026gt;\u0026gt; nestedFuture = CompletableFuture.supplyAsync(() -\u0026gt; { System.out.println(\u0026#34;First task in thenApply: \u0026#34; + Thread.currentThread().getName()); return \u0026#34;user123\u0026#34;; }, executor).thenApply(userId -\u0026gt; { // This returns a CompletableFuture, but it gets wrapped in another CompletableFuture return CompletableFuture.supplyAsync(() -\u0026gt; { System.out.println(\u0026#34;Second task in thenApply: \u0026#34; + Thread.currentThread().getName()); return \u0026#34;User details for: \u0026#34; + userId; }, executor); }); // Using thenCompose - flattens the nested CompletableFuture CompletableFuture\u0026lt;String\u0026gt; flatFuture = CompletableFuture.supplyAsync(() -\u0026gt; { System.out.println(\u0026#34;First task in thenCompose: \u0026#34; + Thread.currentThread().getName()); return \u0026#34;user123\u0026#34;; }, executor).thenCompose(userId -\u0026gt; { // This returns a CompletableFuture, and thenCompose flattens it return CompletableFuture.supplyAsync(() -\u0026gt; { System.out.println(\u0026#34;Second task in thenCompose: \u0026#34; + Thread.currentThread().getName()); return \u0026#34;User details for: \u0026#34; + userId; }, executor); }); System.out.println(\u0026#34;thenApply result type: \u0026#34; + nestedFuture.get().get()); // Note the double get() System.out.println(\u0026#34;thenCompose result type: \u0026#34; + flatFuture.get()); // Single get() 1 2 3 4 5 6 7 === thenApply vs thenCompose Difference === First task in thenApply: pool-1-thread-1 Second task in thenApply: pool-1-thread-2 First task in thenCompose: pool-1-thread-3 thenApply result type: User details for: user123 Second task in thenCompose: pool-1-thread-4 thenCompose result type: User details for: user123 Exception Handling whenComplete The whenComplete method is called when the CompletableFuture completes, regardless of whether it completed successfully or exceptionally.\nIf the CompletableFuture completes successfully, the whenComplete method receives the result and the exception is null.\nIf the CompletableFuture completes exceptionally, the whenComplete method receives null as the result and the exception.\nThe exception will be thrown if the get method is called on the CompletableFuture and the exception is not swallowed.\n1 2 3 4 5 public CompletableFuture\u0026lt;T\u0026gt; whenComplete(BiConsumer\u0026lt;? super T,? super Throwable\u0026gt; action) public CompletableFuture\u0026lt;T\u0026gt; whenCompleteAsync(BiConsumer\u0026lt;? super T,? super Throwable\u0026gt; action) public CompletableFuture\u0026lt;T\u0026gt; whenCompleteAsync(BiConsumer\u0026lt;? super T,? super Throwable\u0026gt; action, Executor executor) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 // Example 1: Successful completion System.out.println(\u0026#34;\\n=== Successful Completion Example ===\u0026#34;); CompletableFuture\u0026lt;Integer\u0026gt; successFuture = CompletableFuture .supplyAsync(() -\u0026gt; { System.out.println(\u0026#34;Calculating result in thread: \u0026#34; + Thread.currentThread().getName()); return 42; }, executor) .whenComplete((result, ex) -\u0026gt; { if (ex == null) { System.out.println(\u0026#34;Operation completed successfully with result: \u0026#34; + result); } else { System.out.println(\u0026#34;Operation failed with exception: \u0026#34; + ex.getMessage()); } System.out.println(\u0026#34;whenComplete running in thread: \u0026#34; + Thread.currentThread().getName()); }); System.out.println(\u0026#34;Success result: \u0026#34; + successFuture.get()); // Example 2: Exceptional completion System.out.println(\u0026#34;\\n=== Exceptional Completion Example ===\u0026#34;); CompletableFuture\u0026lt;Integer\u0026gt; errorFuture = CompletableFuture .\u0026lt;Integer\u0026gt;supplyAsync(() -\u0026gt; { System.out.println(\u0026#34;Throwing exception in thread: \u0026#34; + Thread.currentThread().getName()); throw new IllegalStateException(\u0026#34;Simulated error\u0026#34;); }, executor) .whenComplete((result, ex) -\u0026gt; { if (ex == null) { System.out.println(\u0026#34;Operation completed successfully with result: \u0026#34; + result); } else { System.out.println(\u0026#34;Operation failed with exception: \u0026#34; + ex.getMessage()); } System.out.println(\u0026#34;whenComplete running in thread: \u0026#34; + Thread.currentThread().getName()); }); try { errorFuture.get(); // This will throw an exception } catch (Exception e) { System.out.println(\u0026#34;Caught exception from get(): \u0026#34; + e.getCause().getMessage()); } 1 2 3 4 5 6 7 8 9 10 11 === Successful Completion Example === Calculating result in thread: pool-1-thread-1 Operation completed successfully with result: 42 whenComplete running in thread: pool-1-thread-1 Success result: 42 === Exceptional Completion Example === Throwing exception in thread: pool-1-thread-2 Operation failed with exception: java.lang.IllegalStateException: Simulated error whenComplete running in thread: pool-1-thread-2 Caught exception from get(): Simulated error exceptionally the exceptionally method is called when the CompletableFuture completes exceptionally. 1 public CompletableFuture\u0026lt;T\u0026gt; exceptionally(Function\u0026lt;Throwable,? extends T\u0026gt; fn) 1 2 3 4 5 6 7 8 9 10 System.out.println(\u0026#34;\\n=== Basic Exception Handling ===\u0026#34;); CompletableFuture\u0026lt;Integer\u0026gt; divisionFuture = CompletableFuture.supplyAsync(() -\u0026gt; { System.out.println(\u0026#34;Attempting division...\u0026#34;); return 100 / 0; // Will throw ArithmeticException }, executor).exceptionally(throwable -\u0026gt; { System.out.println(\u0026#34;Exception caught: \u0026#34; + throwable.getMessage()); return -1; // Return default value in case of error }); System.out.println(\u0026#34;Division result: \u0026#34; + divisionFuture.get()); 1 2 3 4 === Basic Exception Handling === Attempting division... Exception caught: java.lang.ArithmeticException: / by zero Division result: -1 Common Issues \u0026amp; Notes Slient Failures 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 // WRONG - Exception gets swallowed CompletableFuture.supplyAsync(() -\u0026gt; { throw new RuntimeException(\u0026#34;Error\u0026#34;); }).thenAccept(result -\u0026gt; { // This never executes due to exception System.out.println(result); }); // CORRECT - Handle the exception CompletableFuture.supplyAsync(() -\u0026gt; { throw new RuntimeException(\u0026#34;Error\u0026#34;); }).whenComplete((result, ex) -\u0026gt; { if (ex != null) { System.err.println(\u0026#34;Error occurred: \u0026#34; + ex.getMessage()); } }).exceptionally(throwable -\u0026gt; { // Provide fallback value return null; }); Chain Breaking 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 // WRONG - Chain breaks after exception CompletableFuture.supplyAsync(() -\u0026gt; { throw new RuntimeException(\u0026#34;Error\u0026#34;); }).thenApply(result -\u0026gt; { return \u0026#34;Processed: \u0026#34; + result; // Never executes }).thenAccept(System.out::println); // CORRECT - Handle exception and continue chain CompletableFuture.supplyAsync(() -\u0026gt; { throw new RuntimeException(\u0026#34;Error\u0026#34;); }).exceptionally(ex -\u0026gt; { return \u0026#34;Default Value\u0026#34;; // Provide fallback }).thenApply(result -\u0026gt; { return \u0026#34;Processed: \u0026#34; + result; // Continues with fallback value }).thenAccept(System.out::println); Exception Propagation in Composed Futures 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 // WRONG - Lost exception in nested future CompletableFuture.supplyAsync(() -\u0026gt; { return CompletableFuture.supplyAsync(() -\u0026gt; { throw new RuntimeException(\u0026#34;Nested Error\u0026#34;); }); }).thenAccept(System.out::println); // CORRECT - Use thenCompose to properly propagate exceptions CompletableFuture.supplyAsync(() -\u0026gt; \u0026#34;value\u0026#34;) .thenCompose(value -\u0026gt; CompletableFuture.supplyAsync(() -\u0026gt; { throw new RuntimeException(\u0026#34;Nested Error\u0026#34;); })) .exceptionally(ex -\u0026gt; { System.err.println(\u0026#34;Caught: \u0026#34; + ex.getMessage()); return \u0026#34;fallback\u0026#34;; }); Lost Context in Async Methods 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 // WRONG - Exception context might be lost CompletableFuture.supplyAsync(() -\u0026gt; { throw new RuntimeException(\u0026#34;Original error\u0026#34;); }).thenApplyAsync(result -\u0026gt; { // Exception context might be different thread return result; }); // CORRECT - Preserve context with proper exception handling CompletableFuture.supplyAsync(() -\u0026gt; { throw new RuntimeException(\u0026#34;Original error\u0026#34;); }).whenComplete((result, ex) -\u0026gt; { // Capture exception context here if (ex != null) { // Log with full context logger.error(\u0026#34;Operation failed\u0026#34;, ex); } }); Exception Recovery Patterns 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 CompletableFuture\u0026lt;String\u0026gt; future = CompletableFuture .supplyAsync(() -\u0026gt; { if (something) throw new RuntimeException(\u0026#34;Error\u0026#34;); return \u0026#34;result\u0026#34;; }) .exceptionally(ex -\u0026gt; { if (ex instanceof RuntimeException) { return \u0026#34;recovered\u0026#34;; } throw new CompletionException(ex); }) .whenComplete((result, ex) -\u0026gt; { // Log final outcome if (ex != null) { logger.error(\u0026#34;Operation failed\u0026#34;, ex); } else { logger.info(\u0026#34;Operation succeeded with: \u0026#34; + result); } }); Handling Checked Exceptions 1 2 3 4 5 6 7 8 9 10 11 12 13 // WRONG - Checked exceptions must be wrapped CompletableFuture.supplyAsync(() -\u0026gt; { throw new IOException(); // Won\u0026#39;t compile }); // CORRECT - Wrap checked exceptions CompletableFuture.supplyAsync(() -\u0026gt; { try { throw new IOException(); } catch (IOException e) { throw new CompletionException(e); } }); Global Exception Handler 1 2 3 4 // Set up global exception handler for uncaught exceptions Thread.setDefaultUncaughtExceptionHandler((thread, throwable) -\u0026gt; { logger.error(\u0026#34;Uncaught async exception\u0026#34;, throwable); }); Combination Two Tasks AND: thenCombine/thenAcceptBoth/thenAfterBoth These 3 methods are used to combine the results of 2 CompletableFutures then execute the 3rd task.\nthenCombine can get the results of both CompletableFutures and return a value.\nthenAcceptBoth can get the results of both CompletableFutures but does not return a value.\nthenAfterBoth does not get the results of both CompletableFutures and does not return a value.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 // Example 1: thenCombine System.out.println(\u0026#34;\\n=== thenCombine Example ===\u0026#34;); CompletableFuture\u0026lt;Double\u0026gt; priceF = CompletableFuture.supplyAsync(() -\u0026gt; { System.out.println(\u0026#34;Calculating price in thread: \u0026#34; + Thread.currentThread().getName()); return 100.0; }, executor); CompletableFuture\u0026lt;Double\u0026gt; discountF = CompletableFuture.supplyAsync(() -\u0026gt; { System.out.println(\u0026#34;Calculating discount in thread: \u0026#34; + Thread.currentThread().getName()); return 0.2; // 20% discount }, executor); CompletableFuture\u0026lt;Double\u0026gt; finalPriceF = priceF.thenCombine(discountF, (price, discount) -\u0026gt; { System.out.println(\u0026#34;Combining price and discount in thread: \u0026#34; + Thread.currentThread().getName()); return price * (1 - discount); }); System.out.println(\u0026#34;Final price after discount: $\u0026#34; + finalPriceF.get()); // Example 2: thenAcceptBoth System.out.println(\u0026#34;\\n=== thenAcceptBoth Example ===\u0026#34;); CompletableFuture\u0026lt;String\u0026gt; userF = CompletableFuture.supplyAsync(() -\u0026gt; { System.out.println(\u0026#34;Fetching user in thread: \u0026#34; + Thread.currentThread().getName()); return \u0026#34;John Doe\u0026#34;; }, executor); CompletableFuture\u0026lt;Integer\u0026gt; orderCountF = CompletableFuture.supplyAsync(() -\u0026gt; { System.out.println(\u0026#34;Fetching order count in thread: \u0026#34; + Thread.currentThread().getName()); return 5; }, executor); userF.thenAcceptBoth(orderCountF, (user, orderCount) -\u0026gt; { System.out.println(\u0026#34;Processing in thread: \u0026#34; + Thread.currentThread().getName()); System.out.println(\u0026#34;User \u0026#34; + user + \u0026#34; has placed \u0026#34; + orderCount + \u0026#34; orders\u0026#34;); }).get(); // Example 3: runAfterBoth System.out.println(\u0026#34;\\n=== runAfterBoth Example ===\u0026#34;); CompletableFuture\u0026lt;Void\u0026gt; cacheUpdateF = CompletableFuture.runAsync(() -\u0026gt; { System.out.println(\u0026#34;Updating cache in thread: \u0026#34; + Thread.currentThread().getName()); System.out.println(\u0026#34;Cache update completed\u0026#34;); }, executor); CompletableFuture\u0026lt;Void\u0026gt; dbUpdateF = CompletableFuture.runAsync(() -\u0026gt; { System.out.println(\u0026#34;Updating database in thread: \u0026#34; + Thread.currentThread().getName()); System.out.println(\u0026#34;Database update completed\u0026#34;); }, executor); cacheUpdateF.runAfterBoth(dbUpdateF, () -\u0026gt; { System.out.println(\u0026#34;Running final task in thread: \u0026#34; + Thread.currentThread().getName()); System.out.println(\u0026#34;All updates completed - sending notification\u0026#34;); }).get(); 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 === thenCombine Example === Calculating discount in thread: pool-1-thread-2 Calculating price in thread: pool-1-thread-1 Combining price and discount in thread: main Final price after discount: $80.0 === thenAcceptBoth Example === Fetching user in thread: pool-1-thread-3 Fetching order count in thread: pool-1-thread-2 Processing in thread: main User John Doe has placed 5 orders === runAfterBoth Example === Updating cache in thread: pool-1-thread-1 Cache update completed Updating database in thread: pool-1-thread-3 Database update completed Running final task in thread: main All updates completed - sending notification Two Tasks OR: applyToEither/acceptEither/runAfterEither These 3 methods are used to execute the 3rd task when either of the 2 CompletableFutures completes.\napplyToEither can get the result of the first completed CompletableFuture and return a value.\nacceptEither can get the result of the first completed CompletableFuture but does not return a value.\nrunAfterEither does not get the result of the first completed CompletableFuture and does not return a value.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 // Example 1: applyToEither - Get price from fastest responding service System.out.println(\u0026#34;\\n=== applyToEither Example ===\u0026#34;); CompletableFuture\u0026lt;Double\u0026gt; service1Price = CompletableFuture.supplyAsync(() -\u0026gt; { System.out.println(\u0026#34;Service 1 checking price in thread: \u0026#34; + Thread.currentThread().getName()); sleep(2000); // Slower service return 100.50; }, executor); CompletableFuture\u0026lt;Double\u0026gt; service2Price = CompletableFuture.supplyAsync(() -\u0026gt; { System.out.println(\u0026#34;Service 2 checking price in thread: \u0026#34; + Thread.currentThread().getName()); sleep(1000); // Faster service return 99.99; }, executor); CompletableFuture\u0026lt;String\u0026gt; fastestPrice = service1Price.applyToEither(service2Price, price -\u0026gt; { System.out.println(\u0026#34;Processing fastest price in thread: \u0026#34; + Thread.currentThread().getName()); return String.format(\u0026#34;Best available price: $%.2f\u0026#34;, price); }); System.out.println(fastestPrice.get()); // Example 2: acceptEither - Log first available weather data System.out.println(\u0026#34;\\n=== acceptEither Example ===\u0026#34;); CompletableFuture\u0026lt;String\u0026gt; primaryWeather = CompletableFuture.supplyAsync(() -\u0026gt; { System.out.println(\u0026#34;Primary weather service in thread: \u0026#34; + Thread.currentThread().getName()); sleep(2000); // Slower service return \u0026#34;Sunny, 25°C\u0026#34;; }, executor); CompletableFuture\u0026lt;String\u0026gt; backupWeather = CompletableFuture.supplyAsync(() -\u0026gt; { System.out.println(\u0026#34;Backup weather service in thread: \u0026#34; + Thread.currentThread().getName()); sleep(1000); // Faster service return \u0026#34;Sunny, 26°C\u0026#34;; }, executor); primaryWeather.acceptEither(backupWeather, weather -\u0026gt; { System.out.println(\u0026#34;Processing weather data in thread: \u0026#34; + Thread.currentThread().getName()); System.out.println(\u0026#34;Current weather: \u0026#34; + weather); }).get(); // Example 3: runAfterEither - Notification after first cache update System.out.println(\u0026#34;\\n=== runAfterEither Example ===\u0026#34;); CompletableFuture\u0026lt;Void\u0026gt; primaryCache = CompletableFuture.runAsync(() -\u0026gt; { System.out.println(\u0026#34;Updating primary cache in thread: \u0026#34; + Thread.currentThread().getName()); sleep(2000); System.out.println(\u0026#34;Primary cache updated\u0026#34;); }, executor); CompletableFuture\u0026lt;Void\u0026gt; backupCache = CompletableFuture.runAsync(() -\u0026gt; { System.out.println(\u0026#34;Updating backup cache in thread: \u0026#34; + Thread.currentThread().getName()); sleep(1000); System.out.println(\u0026#34;Backup cache updated\u0026#34;); }, executor); primaryCache.runAfterEither(backupCache, () -\u0026gt; { System.out.println(\u0026#34;Running notification in thread: \u0026#34; + Thread.currentThread().getName()); System.out.println(\u0026#34;Cache system is now updated\u0026#34;); }).get(); 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 === applyToEither Example === Service 1 checking price in thread: pool-1-thread-1 Service 2 checking price in thread: pool-1-thread-2 Processing fastest price in thread: pool-1-thread-2 Best available price: $99.99 === acceptEither Example === Primary weather service in thread: pool-1-thread-3 Backup weather service in thread: pool-1-thread-2 Processing weather data in thread: pool-1-thread-2 Current weather: Sunny, 26°C === runAfterEither Example === Updating primary cache in thread: pool-1-thread-1 Updating backup cache in thread: pool-1-thread-2 Backup cache updated Running notification in thread: pool-1-thread-2 Cache system is now updated Multiple Tasks: allOf/anyOf The allOf method is used to execute a task after all CompletableFutures complete.\nThe anyOf method is used to execute a task after any CompletableFuture completes.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 // Example 1: allOf with data aggregation System.out.println(\u0026#34;\\n=== allOf Example - Product Details ===\u0026#34;); CompletableFuture\u0026lt;String\u0026gt; productDetails = CompletableFuture.supplyAsync(() -\u0026gt; { System.out.println(\u0026#34;Fetching product details in thread: \u0026#34; + Thread.currentThread().getName()); sleep(1000); return \u0026#34;Laptop XPS 15\u0026#34;; }, executor); CompletableFuture\u0026lt;Double\u0026gt; productPrice = CompletableFuture.supplyAsync(() -\u0026gt; { System.out.println(\u0026#34;Fetching price in thread: \u0026#34; + Thread.currentThread().getName()); sleep(1500); return 1299.99; }, executor); CompletableFuture\u0026lt;Integer\u0026gt; productStock = CompletableFuture.supplyAsync(() -\u0026gt; { System.out.println(\u0026#34;Checking stock in thread: \u0026#34; + Thread.currentThread().getName()); sleep(1000); return 50; }, executor); CompletableFuture\u0026lt;Void\u0026gt; allDetails = CompletableFuture.allOf( productDetails, productPrice, productStock); allDetails.thenRun(() -\u0026gt; { try { System.out.println(\u0026#34;\\nAll product information gathered:\u0026#34;); System.out.println(\u0026#34;Product: \u0026#34; + productDetails.get()); System.out.println(\u0026#34;Price: $\u0026#34; + productPrice.get()); System.out.println(\u0026#34;Stock: \u0026#34; + productStock.get() + \u0026#34; units\u0026#34;); } catch (Exception e) { e.printStackTrace(); } }).get(); // Example 2: anyOf with multiple data sources System.out.println(\u0026#34;\\n=== anyOf Example - Multiple Data Sources ===\u0026#34;); CompletableFuture\u0026lt;String\u0026gt; primaryDb = CompletableFuture.supplyAsync(() -\u0026gt; { System.out.println(\u0026#34;Querying primary database in thread: \u0026#34; + Thread.currentThread().getName()); sleep(2000); // Slow response return \u0026#34;Data from Primary DB\u0026#34;; }, executor); CompletableFuture\u0026lt;String\u0026gt; secondaryDb = CompletableFuture.supplyAsync(() -\u0026gt; { System.out.println(\u0026#34;Querying secondary database in thread: \u0026#34; + Thread.currentThread().getName()); sleep(1000); // Faster response return \u0026#34;Data from Secondary DB\u0026#34;; }, executor); CompletableFuture\u0026lt;String\u0026gt; cache = CompletableFuture.supplyAsync(() -\u0026gt; { System.out.println(\u0026#34;Checking cache in thread: \u0026#34; + Thread.currentThread().getName()); sleep(500); // Fastest response return \u0026#34;Data from Cache\u0026#34;; }, executor); CompletableFuture\u0026lt;Object\u0026gt; firstResponse = CompletableFuture.anyOf(primaryDb, secondaryDb, cache); System.out.println(\u0026#34;First available response: \u0026#34; + firstResponse.get()); 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 === allOf Example - Product Details === Fetching product details in thread: pool-1-thread-1 Fetching price in thread: pool-1-thread-2 Checking stock in thread: pool-1-thread-3 All product information gathered: Product: Laptop XPS 15 Price: $1299.99 Stock: 50 units === anyOf Example - Multiple Data Sources === Querying primary database in thread: pool-1-thread-4 Querying secondary database in thread: pool-1-thread-3 Checking cache in thread: pool-1-thread-1 First available response: Data from Cache Summary CompletableFuture is a powerful tool for asynchronous programming in Java. It allows developers to write non-blocking code and execute tasks in parallel. By understanding how to use CompletableFuture effectively, developers can improve the performance of their applications and create more responsive user experiences. This post has provided a comprehensive guide to using CompletableFuture in Java, including examples of how to use the various methods available.\n","date":"2024-12-08T00:00:00Z","permalink":"https://bytelife-s.github.io/p/java-async-programming-completablefuture/","title":"Java Async Programming - CompletableFuture"},{"content":"Problem In our recent work, we encountered a problem where we changed the secret in the vault and updated the way to retrieve it. This change didn\u0026rsquo;t cause any issues during local testing, but problems arose after deploying to staging. We hope to check what is being used in remote environments so that we can determine whether there\u0026rsquo;s an issue with our retrieval method or if there\u0026rsquo;s a problem with the secret itself.\nThis kind of issue is common in automated deployment environments because stg/prd usually involves a series of automatic injections and startup scripts. Therefore, this method helps us check conflicts between local and remote automated deployments.\nDebug Env Setup First, we create a demo service with a single endpoint and an injected value.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 package com.example.demo; import org.springframework.beans.factory.annotation.Value; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RestController; @RestController public class DemoService { @Value(\u0026#34;${demo.value}\u0026#34;) private String stringValue; @GetMapping(\u0026#34;/demo\u0026#34;) public String getStringValue() { return stringValue; } } Next, we input the value into the application.yaml config. This value can be overridden by an injected environment variable.\n1 2 demo: value: ${DEMO_VALUE:123} Finally, we can construct the Docker image and run it to mimic the service deployment in a remote environment.\n1 2 CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES c64090609d8a demo \u0026#34;java -jar app.jar\u0026#34; 8 seconds ago Up 7 seconds 0.0.0.0:8080-\u0026gt;8080/tcp charming_chatterjee Install Arthas Arthas allows developers to troubleshoot production issues for Java applications without modifying code or restarting servers.\n1 2 3 4 5 6 7 # log into container docker exec -ti c64090609d8a bash # install and start arthas bash-4.4# curl -O https://arthas.aliyun.com/arthas-boot.jar bash-4.4# java -jar arthas-boot.jar Check the target service We need to locate the target service bean within the Spring Context. A simple method is to monitor the Spring bean, so we do not need to manually create a custom bean with ApplicationContextAware.\n1 tt -t org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter invokeHandlerMethod Arthas assists in marking the target, allowing us to retrieve the application context and examine the bean as needed. The index from the previous step is 1000.\n1 tt -i 1000 -w \u0026#39;target.getApplicationContext().getBean(\u0026#34;demoService\u0026#34;)\u0026#39; We\u0026rsquo;ve noted that the injected value is 123, showing we can retrieve this value from the remote runtime.\nIn our case, the service\u0026rsquo;s injected value didn\u0026rsquo;t meet our expectations. So we traced the problem to a conflict in retrieving this value from the automated deployment pipeline and have since resolved it.\nMore Usecase The above workflow has more applications. For instance, we can invoke the method in the bean to verify if the outcome is as expected.\n1 2 3 [arthas@1]$ tt -i 1000 -w \u0026#39;target.getApplicationContext().getBean(\u0026#34;demoService\u0026#34;).getStringValue()\u0026#39; @String[123] #ffect(row-cnt:1) cost in 1 ms. Or we can use ognl to check more info for static methods or property. For example, we can create a custom bean and implement ApplicationContextAware interface, set the context as static property, then we can use ognl to get context directly.\n1 2 3 sc -d com.xxx.SpringContexDemo ognl -c \u0026lt;index\u0026gt; \u0026#39;@com.xxx.SpringContexDemo@getApplicationContext()\u0026#39; Summary This debugging workflow allows us to access the ApplicationContext in a remote environment, aiding online issue resolution. It\u0026rsquo;s not just useful for verifying injected values; it can also help resolve more complex issues since we have access to the context and all its beans.\nReference https://github.com/alibaba/arthas\nhttps://github.com/alibaba/arthas/issues/482\n","date":"2024-03-09T00:00:00Z","permalink":"https://bytelife-s.github.io/p/check-injected-value-in-remotely-running-springboot-application/","title":"Check Bean and Config in Remotely Running SpringBoot Application"}]